{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brennan/anaconda3/envs/analytics/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "import xgboost\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, Imputer, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "ids = test['PassengerId']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891 418\n"
     ]
    }
   ],
   "source": [
    "print(len(df), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "866\n"
     ]
    }
   ],
   "source": [
    "t = np.count_nonzero(df.isnull().values)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 8)\n",
      "(891, 8)\n",
      "(418, 7)\n",
      "(418, 7)\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['Ticket','Cabin', 'PassengerId', 'Name'], axis=1)\n",
    "# Remove NaN values\n",
    "print(df.shape)\n",
    "# df = df.dropna()\n",
    "print(df.shape)\n",
    "\n",
    "test = test.drop(['Ticket','Cabin', 'PassengerId', 'Name'], axis=1)\n",
    "print(test.shape)\n",
    "# test = test.dropna()\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['sex_f'] = np.where(df['Sex'] == 'female', 1, 0)\n",
    "test['sex_f'] = np.where(test['Sex'] == 'female', 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embarked_dum = pd.get_dummies(df['Embarked'], prefix='Embarked')\n",
    "embarked_dum2 = pd.get_dummies(test['Embarked'], prefix='Embarked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.concat([df, embarked_dum], axis=1)\n",
    "test = pd.concat([test, embarked_dum2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.drop(['Embarked','Sex'], axis=1)\n",
    "test = test.drop(['Embarked','Sex'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'sex_f', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n",
      "['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'sex_f', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>sex_f</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.2250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>82.2667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>61.1750</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.3500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>59.4000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1708</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.6833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>61.3792</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>262.3750</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>61.9792</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21.6792</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39.4000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>2</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79.2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>164.8667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>59.4000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.8625</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>2</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>211.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7208</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.7750</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>3</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>3</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass   Age  SibSp  Parch      Fare  sex_f  Embarked_C  Embarked_Q  \\\n",
       "0         3  34.5      0      0    7.8292      0           0           1   \n",
       "1         3  47.0      1      0    7.0000      1           0           0   \n",
       "2         2  62.0      0      0    9.6875      0           0           1   \n",
       "3         3  27.0      0      0    8.6625      0           0           0   \n",
       "4         3  22.0      1      1   12.2875      1           0           0   \n",
       "5         3  14.0      0      0    9.2250      0           0           0   \n",
       "6         3  30.0      0      0    7.6292      1           0           1   \n",
       "7         2  26.0      1      1   29.0000      0           0           0   \n",
       "8         3  18.0      0      0    7.2292      1           1           0   \n",
       "9         3  21.0      2      0   24.1500      0           0           0   \n",
       "10        3   NaN      0      0    7.8958      0           0           0   \n",
       "11        1  46.0      0      0   26.0000      0           0           0   \n",
       "12        1  23.0      1      0   82.2667      1           0           0   \n",
       "13        2  63.0      1      0   26.0000      0           0           0   \n",
       "14        1  47.0      1      0   61.1750      1           0           0   \n",
       "15        2  24.0      1      0   27.7208      1           1           0   \n",
       "16        2  35.0      0      0   12.3500      0           0           1   \n",
       "17        3  21.0      0      0    7.2250      0           1           0   \n",
       "18        3  27.0      1      0    7.9250      1           0           0   \n",
       "19        3  45.0      0      0    7.2250      1           1           0   \n",
       "20        1  55.0      1      0   59.4000      0           1           0   \n",
       "21        3   9.0      0      1    3.1708      0           0           0   \n",
       "22        1   NaN      0      0   31.6833      1           0           0   \n",
       "23        1  21.0      0      1   61.3792      0           1           0   \n",
       "24        1  48.0      1      3  262.3750      1           1           0   \n",
       "25        3  50.0      1      0   14.5000      0           0           0   \n",
       "26        1  22.0      0      1   61.9792      1           1           0   \n",
       "27        3  22.5      0      0    7.2250      0           1           0   \n",
       "28        1  41.0      0      0   30.5000      0           0           0   \n",
       "29        3   NaN      2      0   21.6792      0           1           0   \n",
       "..      ...   ...    ...    ...       ...    ...         ...         ...   \n",
       "388       3  21.0      0      0    7.7500      0           0           1   \n",
       "389       3   6.0      3      1   21.0750      0           0           0   \n",
       "390       1  23.0      0      0   93.5000      0           0           0   \n",
       "391       1  51.0      0      1   39.4000      1           0           0   \n",
       "392       3  13.0      0      2   20.2500      0           0           0   \n",
       "393       2  47.0      0      0   10.5000      0           0           0   \n",
       "394       3  29.0      3      1   22.0250      0           0           0   \n",
       "395       1  18.0      1      0   60.0000      1           0           0   \n",
       "396       3  24.0      0      0    7.2500      0           0           1   \n",
       "397       1  48.0      1      1   79.2000      1           1           0   \n",
       "398       3  22.0      0      0    7.7750      0           0           0   \n",
       "399       3  31.0      0      0    7.7333      0           0           1   \n",
       "400       1  30.0      0      0  164.8667      1           0           0   \n",
       "401       2  38.0      1      0   21.0000      0           0           0   \n",
       "402       1  22.0      0      1   59.4000      1           1           0   \n",
       "403       1  17.0      0      0   47.1000      0           0           0   \n",
       "404       1  43.0      1      0   27.7208      0           1           0   \n",
       "405       2  20.0      0      0   13.8625      0           1           0   \n",
       "406       2  23.0      1      0   10.5000      0           0           0   \n",
       "407       1  50.0      1      1  211.5000      0           1           0   \n",
       "408       3   NaN      0      0    7.7208      1           0           1   \n",
       "409       3   3.0      1      1   13.7750      1           0           0   \n",
       "410       3   NaN      0      0    7.7500      1           0           1   \n",
       "411       1  37.0      1      0   90.0000      1           0           1   \n",
       "412       3  28.0      0      0    7.7750      1           0           0   \n",
       "413       3   NaN      0      0    8.0500      0           0           0   \n",
       "414       1  39.0      0      0  108.9000      1           1           0   \n",
       "415       3  38.5      0      0    7.2500      0           0           0   \n",
       "416       3   NaN      0      0    8.0500      0           0           0   \n",
       "417       3   NaN      1      1   22.3583      0           1           0   \n",
       "\n",
       "     Embarked_S  \n",
       "0             0  \n",
       "1             1  \n",
       "2             0  \n",
       "3             1  \n",
       "4             1  \n",
       "5             1  \n",
       "6             0  \n",
       "7             1  \n",
       "8             0  \n",
       "9             1  \n",
       "10            1  \n",
       "11            1  \n",
       "12            1  \n",
       "13            1  \n",
       "14            1  \n",
       "15            0  \n",
       "16            0  \n",
       "17            0  \n",
       "18            1  \n",
       "19            0  \n",
       "20            0  \n",
       "21            1  \n",
       "22            1  \n",
       "23            0  \n",
       "24            0  \n",
       "25            1  \n",
       "26            0  \n",
       "27            0  \n",
       "28            1  \n",
       "29            0  \n",
       "..          ...  \n",
       "388           0  \n",
       "389           1  \n",
       "390           1  \n",
       "391           1  \n",
       "392           1  \n",
       "393           1  \n",
       "394           1  \n",
       "395           1  \n",
       "396           0  \n",
       "397           0  \n",
       "398           1  \n",
       "399           0  \n",
       "400           1  \n",
       "401           1  \n",
       "402           0  \n",
       "403           1  \n",
       "404           0  \n",
       "405           0  \n",
       "406           1  \n",
       "407           0  \n",
       "408           0  \n",
       "409           1  \n",
       "410           0  \n",
       "411           0  \n",
       "412           1  \n",
       "413           1  \n",
       "414           0  \n",
       "415           1  \n",
       "416           1  \n",
       "417           0  \n",
       "\n",
       "[418 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(train))\n",
    "print(list(test))\n",
    "cols = test[[c for c in test if 'Survived' not in c]]\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train[[c for c in train if 'Survived' not in c]]\n",
    "y = train['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = Pipeline([\n",
    "    ('impute', Imputer(missing_values='NaN', strategy='mean', axis=0)),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "X_train_sc = preprocessing.fit_transform(X_train)\n",
    "X_test_sc = preprocessing.transform(X_test)\n",
    "test = preprocessing.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 9)\n",
      "(179, 9)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_sc.shape)\n",
    "print(X_test_sc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lr = LogisticRegression()\n",
    "# lr.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preds = lr.predict(X_test_sc)\n",
    "# preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# probs = lr.predict_proba(X_test_sc)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# metrics.accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# metrics.roc_auc_score(y_test, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_preds = lr.predict(X_train_sc)\n",
    "# metrics.accuracy_score(y_train, train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# probs_train = lr.predict_proba(X_train_sc)[:,1]\n",
    "# metrics.roc_auc_score(y_train, probs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# probs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/model_evaluation.html#accuracy-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = {\"max_depth\": [3, None],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"],\n",
    "                \"n_estimators\": [10, 50]}\n",
    "scores = ['roc_auc', 'accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'n_estimators': 50}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.841 (+/-0.079) for {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'n_estimators': 10}\n",
      "0.848 (+/-0.077) for {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'n_estimators': 50}\n",
      "0.832 (+/-0.070) for {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'n_estimators': 10}\n",
      "0.844 (+/-0.075) for {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'n_estimators': 50}\n",
      "0.841 (+/-0.081) for {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 10}\n",
      "0.848 (+/-0.078) for {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 50}\n",
      "0.837 (+/-0.070) for {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'n_estimators': 10}\n",
      "0.844 (+/-0.074) for {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'n_estimators': 50}\n",
      "0.841 (+/-0.083) for {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'n_estimators': 10}\n",
      "0.847 (+/-0.087) for {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'n_estimators': 50}\n",
      "0.811 (+/-0.035) for {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'n_estimators': 10}\n",
      "0.819 (+/-0.043) for {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'n_estimators': 50}\n",
      "0.846 (+/-0.083) for {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 10}\n",
      "0.847 (+/-0.086) for {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 50}\n",
      "0.808 (+/-0.039) for {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'n_estimators': 10}\n",
      "0.813 (+/-0.051) for {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'n_estimators': 50}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.95      0.85       105\n",
      "          1       0.90      0.59      0.72        74\n",
      "\n",
      "avg / total       0.82      0.80      0.79       179\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'n_estimators': 50}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.806 (+/-0.092) for {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'n_estimators': 10}\n",
      "0.819 (+/-0.085) for {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'n_estimators': 50}\n",
      "0.791 (+/-0.057) for {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'n_estimators': 10}\n",
      "0.801 (+/-0.047) for {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'n_estimators': 50}\n",
      "0.802 (+/-0.097) for {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 10}\n",
      "0.819 (+/-0.093) for {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 50}\n",
      "0.798 (+/-0.036) for {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'n_estimators': 10}\n",
      "0.798 (+/-0.048) for {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'n_estimators': 50}\n",
      "0.815 (+/-0.082) for {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'n_estimators': 10}\n",
      "0.810 (+/-0.082) for {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'n_estimators': 50}\n",
      "0.796 (+/-0.035) for {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'n_estimators': 10}\n",
      "0.785 (+/-0.043) for {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'n_estimators': 50}\n",
      "0.808 (+/-0.083) for {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 10}\n",
      "0.815 (+/-0.073) for {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 50}\n",
      "0.787 (+/-0.036) for {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'n_estimators': 10}\n",
      "0.789 (+/-0.053) for {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'n_estimators': 50}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.95      0.85       105\n",
      "          1       0.90      0.59      0.72        74\n",
      "\n",
      "avg / total       0.82      0.80      0.79       179\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(RandomForestClassifier(random_state=1), tuned_parameters, cv=5,\n",
    "                       scoring=score)\n",
    "    clf.fit(X_train_sc, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test_sc)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 0.38 seconds for 8 candidates parameter settings.\n",
      "\n",
      "0.806 (+/-0.092) for {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'n_estimators': 10}\n",
      "0.819 (+/-0.085) for {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'n_estimators': 50}\n",
      "0.791 (+/-0.057) for {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'n_estimators': 10}\n",
      "0.801 (+/-0.047) for {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'n_estimators': 50}\n",
      "0.802 (+/-0.097) for {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 10}\n",
      "0.819 (+/-0.093) for {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 50}\n",
      "0.798 (+/-0.036) for {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'n_estimators': 10}\n",
      "0.798 (+/-0.048) for {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'n_estimators': 50}\n",
      "0.815 (+/-0.082) for {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'n_estimators': 10}\n",
      "0.810 (+/-0.082) for {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'n_estimators': 50}\n",
      "0.796 (+/-0.035) for {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'n_estimators': 10}\n",
      "0.785 (+/-0.043) for {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'n_estimators': 50}\n",
      "0.808 (+/-0.083) for {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 10}\n",
      "0.815 (+/-0.073) for {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 50}\n",
      "0.787 (+/-0.036) for {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'n_estimators': 10}\n",
      "0.789 (+/-0.053) for {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'n_estimators': 50}\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.97      0.85       105\n",
      "          1       0.93      0.55      0.69        74\n",
      "\n",
      "avg / total       0.83      0.80      0.79       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 8\n",
    "random_search = RandomizedSearchCV(RandomForestClassifier(), param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X_train_sc, y_train)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "y_true, y_pred = y_test, random_search.predict(X_test_sc)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 10.0 estimators: 1 score: 0.784781466577\n",
      "learning rate: 5.0 estimators: 2 score: 0.323586519115\n",
      "learning rate: 3.3333333333333335 estimators: 3 score: 0.719826179298\n",
      "learning rate: 2.5 estimators: 4 score: 0.411967359714\n",
      "learning rate: 2.0 estimators: 5 score: 0.801624189582\n",
      "learning rate: 1.6666666666666667 estimators: 6 score: 0.770753409345\n",
      "learning rate: 1.4285714285714286 estimators: 7 score: 0.782040576794\n",
      "learning rate: 1.25 estimators: 8 score: 0.783350659513\n",
      "learning rate: 1.1111111111111112 estimators: 9 score: 0.797476525822\n",
      "learning rate: 1.0 estimators: 10 score: 0.798845293986\n",
      "learning rate: 0.9090909090909091 estimators: 11 score: 0.788947574335\n",
      "learning rate: 0.8333333333333334 estimators: 12 score: 0.808765369998\n",
      "learning rate: 0.7692307692307693 estimators: 13 score: 0.797498323273\n",
      "learning rate: 0.7142857142857143 estimators: 14 score: 0.808647999106\n",
      "learning rate: 0.6666666666666666 estimators: 15 score: 0.79463894478\n",
      "learning rate: 0.625 estimators: 16 score: 0.800255421417\n",
      "learning rate: 0.5882352941176471 estimators: 17 score: 0.814301922647\n",
      "learning rate: 0.5555555555555556 estimators: 18 score: 0.802755421417\n",
      "learning rate: 0.5263157894736842 estimators: 19 score: 0.804460093897\n",
      "learning rate: 0.5 estimators: 20 score: 0.803091884641\n",
      "learning rate: 0.47619047619047616 estimators: 21 score: 0.818486474402\n",
      "learning rate: 0.45454545454545453 estimators: 22 score: 0.80586910351\n",
      "learning rate: 0.43478260869565216 estimators: 23 score: 0.808745249273\n",
      "learning rate: 0.4166666666666667 estimators: 24 score: 0.814301922647\n",
      "learning rate: 0.4 estimators: 25 score: 0.8073759222\n",
      "learning rate: 0.38461538461538464 estimators: 26 score: 0.807278113123\n",
      "learning rate: 0.37037037037037035 estimators: 27 score: 0.812930918846\n",
      "learning rate: 0.35714285714285715 estimators: 28 score: 0.82553040465\n",
      "learning rate: 0.3448275862068966 estimators: 29 score: 0.817118265146\n",
      "learning rate: 0.3333333333333333 estimators: 30 score: 0.801623630673\n",
      "learning rate: 0.3225806451612903 estimators: 31 score: 0.808706684552\n",
      "learning rate: 0.3125 estimators: 32 score: 0.825490163201\n",
      "learning rate: 0.30303030303030304 estimators: 33 score: 0.811424659066\n",
      "learning rate: 0.29411764705882354 estimators: 34 score: 0.81983623966\n",
      "learning rate: 0.2857142857142857 estimators: 35 score: 0.824102392131\n",
      "learning rate: 0.2777777777777778 estimators: 36 score: 0.814242119383\n",
      "learning rate: 0.2702702702702703 estimators: 37 score: 0.825471160295\n",
      "learning rate: 0.2631578947368421 estimators: 38 score: 0.825510842835\n",
      "learning rate: 0.2564102564102564 estimators: 39 score: 0.819876481109\n",
      "learning rate: 0.25 estimators: 40 score: 0.817038341158\n",
      "learning rate: 0.24390243902439024 estimators: 41 score: 0.817038900067\n",
      "learning rate: 0.23809523809523808 estimators: 42 score: 0.811404538341\n",
      "learning rate: 0.23255813953488372 estimators: 43 score: 0.824061591773\n",
      "learning rate: 0.22727272727272727 estimators: 44 score: 0.811483903421\n",
      "learning rate: 0.2222222222222222 estimators: 45 score: 0.824081712497\n",
      "learning rate: 0.21739130434782608 estimators: 46 score: 0.82691873463\n",
      "learning rate: 0.2127659574468085 estimators: 47 score: 0.821265369998\n",
      "learning rate: 0.20833333333333334 estimators: 48 score: 0.815650011178\n",
      "learning rate: 0.20408163265306123 estimators: 49 score: 0.817039458976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'estimators': 1, 'learning_rate': 10.0, 'score': 0.82691873463000221}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "highest = dict()\n",
    "a = []\n",
    "max_estimators = 50\n",
    "init = 1\n",
    "\n",
    "for i in range(1, max_estimators):\n",
    "    score = cross_val_score(GradientBoostingClassifier(n_estimators=i, learning_rate=10.0/float(i)), \n",
    "                        X_train_sc, y_train, cv=10, scoring='accuracy').mean()\n",
    "    print('learning rate:', 10.0/float(i), 'estimators:', i, 'score:', score)\n",
    "    \n",
    "    if init == 1:\n",
    "        highest['score'] = score\n",
    "        highest['learning_rate'] = 10.0/float(i)\n",
    "        highest['estimators'] = i\n",
    "        init += 1\n",
    "    \n",
    "    if score > highest['score']:\n",
    "        highest['score'] = score\n",
    "        \n",
    "    a.append(score)\n",
    "highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.843 (+/-0.077) for {'C': 0.1}\n",
      "0.843 (+/-0.081) for {'C': 0.3}\n",
      "0.844 (+/-0.081) for {'C': 0.5}\n",
      "0.844 (+/-0.081) for {'C': 0.7}\n",
      "0.844 (+/-0.082) for {'C': 1}\n",
      "0.844 (+/-0.082) for {'C': 10}\n",
      "0.844 (+/-0.082) for {'C': 100}\n",
      "0.844 (+/-0.082) for {'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.82      0.83       105\n",
      "          1       0.75      0.78      0.77        74\n",
      "\n",
      "avg / total       0.81      0.80      0.80       179\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 0.1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.802 (+/-0.094) for {'C': 0.1}\n",
      "0.794 (+/-0.095) for {'C': 0.3}\n",
      "0.795 (+/-0.090) for {'C': 0.5}\n",
      "0.795 (+/-0.090) for {'C': 0.7}\n",
      "0.795 (+/-0.090) for {'C': 1}\n",
      "0.792 (+/-0.101) for {'C': 10}\n",
      "0.792 (+/-0.101) for {'C': 100}\n",
      "0.792 (+/-0.101) for {'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.84      0.84       105\n",
      "          1       0.77      0.77      0.77        74\n",
      "\n",
      "avg / total       0.81      0.81      0.81       179\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'C': [0.1, 0.3, 0.5, 0.7, 1, 10, 100, 1000]}]\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "scores = ['roc_auc', 'accuracy']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(LogisticRegression(random_state=1), tuned_parameters, cv=5,\n",
    "                       scoring=score)\n",
    "    clf.fit(X_train_sc, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test_sc)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.739528083\n",
      "0.849162011173\n"
     ]
    }
   ],
   "source": [
    "gr = GradientBoostingClassifier(n_estimators=1, learning_rate=10, random_state=36, loss='exponential')\n",
    "gr.fit(X_train_sc, y_train)\n",
    "\n",
    "predictions = gr.predict(test)\n",
    "\n",
    "feat_imp = gr.train_score_[0]\n",
    "print(feat_imp)\n",
    "\n",
    "prob = gr.score(X_test_sc, y_test)\n",
    "print(prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived\n",
      "0          892         0\n",
      "1          893         0\n",
      "2          894         1\n",
      "3          895         0\n",
      "4          896         0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\n",
    "output.to_csv('titanic-predictions.csv', index = False)\n",
    "print(output.head())\n",
    "len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
