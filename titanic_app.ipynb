{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, Imputer, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "ids = test['PassengerId']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891 418\n"
     ]
    }
   ],
   "source": [
    "print(len(df), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "866\n"
     ]
    }
   ],
   "source": [
    "t = np.count_nonzero(df.isnull().values)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 8)\n",
      "(891, 8)\n",
      "(418, 7)\n",
      "(418, 7)\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['Ticket','Cabin', 'PassengerId', 'Name'], axis=1)\n",
    "# Remove NaN values\n",
    "print(df.shape)\n",
    "# df = df.dropna()\n",
    "print(df.shape)\n",
    "\n",
    "test = test.drop(['Ticket','Cabin', 'PassengerId', 'Name'], axis=1)\n",
    "print(test.shape)\n",
    "# test = test.dropna()\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['sex_f'] = np.where(df['Sex'] == 'female', 1, 0)\n",
    "test['sex_f'] = np.where(test['Sex'] == 'female', 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embarked_dum = pd.get_dummies(df['Embarked'], prefix='Embarked')\n",
    "embarked_dum2 = pd.get_dummies(test['Embarked'], prefix='Embarked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.concat([df, embarked_dum], axis=1)\n",
    "test = pd.concat([test, embarked_dum2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.drop(['Embarked','Sex'], axis=1)\n",
    "test = test.drop(['Embarked','Sex'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'sex_f', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n",
      "['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'sex_f', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n"
     ]
    }
   ],
   "source": [
    "print(list(train))\n",
    "print(list(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train[[c for c in train if 'Survived' not in c]]\n",
    "y = train['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = Pipeline([\n",
    "    ('impute', Imputer(missing_values='NaN', strategy='mean', axis=0)),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "X_train_sc = preprocessing.fit_transform(X_train)\n",
    "X_test_sc = preprocessing.transform(X_test)\n",
    "test = preprocessing.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 9)\n",
      "(179, 9)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_sc.shape)\n",
    "print(X_test_sc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lr = LogisticRegression()\n",
    "# lr.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preds = lr.predict(X_test_sc)\n",
    "# preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# probs = lr.predict_proba(X_test_sc)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# metrics.accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# metrics.roc_auc_score(y_test, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_preds = lr.predict(X_train_sc)\n",
    "# metrics.accuracy_score(y_train, train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# probs_train = lr.predict_proba(X_train_sc)[:,1]\n",
    "# metrics.roc_auc_score(y_train, probs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# probs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/model_evaluation.html#accuracy-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = {\"max_depth\": [3, None],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"],\n",
    "                \"n_estimators\": [10, 50]}\n",
    "scores = ['roc_auc', 'accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'n_estimators': 50}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.841 (+/-0.079) for {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'n_estimators': 10}\n",
      "0.848 (+/-0.077) for {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'n_estimators': 50}\n",
      "0.832 (+/-0.070) for {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'n_estimators': 10}\n",
      "0.844 (+/-0.075) for {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'n_estimators': 50}\n",
      "0.841 (+/-0.081) for {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 10}\n",
      "0.848 (+/-0.078) for {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 50}\n",
      "0.837 (+/-0.070) for {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'n_estimators': 10}\n",
      "0.844 (+/-0.074) for {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'n_estimators': 50}\n",
      "0.841 (+/-0.083) for {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'n_estimators': 10}\n",
      "0.847 (+/-0.087) for {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'n_estimators': 50}\n",
      "0.811 (+/-0.035) for {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'n_estimators': 10}\n",
      "0.819 (+/-0.043) for {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'n_estimators': 50}\n",
      "0.846 (+/-0.083) for {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 10}\n",
      "0.847 (+/-0.086) for {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 50}\n",
      "0.808 (+/-0.039) for {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'n_estimators': 10}\n",
      "0.813 (+/-0.051) for {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'n_estimators': 50}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.95      0.85       105\n",
      "          1       0.90      0.59      0.72        74\n",
      "\n",
      "avg / total       0.82      0.80      0.79       179\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'n_estimators': 50}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.806 (+/-0.092) for {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'n_estimators': 10}\n",
      "0.819 (+/-0.085) for {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'n_estimators': 50}\n",
      "0.791 (+/-0.057) for {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'n_estimators': 10}\n",
      "0.801 (+/-0.047) for {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'n_estimators': 50}\n",
      "0.802 (+/-0.097) for {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 10}\n",
      "0.819 (+/-0.093) for {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 50}\n",
      "0.798 (+/-0.036) for {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'n_estimators': 10}\n",
      "0.798 (+/-0.048) for {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'n_estimators': 50}\n",
      "0.815 (+/-0.082) for {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'n_estimators': 10}\n",
      "0.810 (+/-0.082) for {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'n_estimators': 50}\n",
      "0.796 (+/-0.035) for {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'n_estimators': 10}\n",
      "0.785 (+/-0.043) for {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'n_estimators': 50}\n",
      "0.808 (+/-0.083) for {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 10}\n",
      "0.815 (+/-0.073) for {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 50}\n",
      "0.787 (+/-0.036) for {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'n_estimators': 10}\n",
      "0.789 (+/-0.053) for {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'n_estimators': 50}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.95      0.85       105\n",
      "          1       0.90      0.59      0.72        74\n",
      "\n",
      "avg / total       0.82      0.80      0.79       179\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(RandomForestClassifier(random_state=1), tuned_parameters, cv=5,\n",
    "                       scoring=score)\n",
    "    clf.fit(X_train_sc, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test_sc)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 0.38 seconds for 8 candidates parameter settings.\n",
      "\n",
      "0.806 (+/-0.092) for {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'n_estimators': 10}\n",
      "0.819 (+/-0.085) for {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'n_estimators': 50}\n",
      "0.791 (+/-0.057) for {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'n_estimators': 10}\n",
      "0.801 (+/-0.047) for {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'n_estimators': 50}\n",
      "0.802 (+/-0.097) for {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 10}\n",
      "0.819 (+/-0.093) for {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 50}\n",
      "0.798 (+/-0.036) for {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'n_estimators': 10}\n",
      "0.798 (+/-0.048) for {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'n_estimators': 50}\n",
      "0.815 (+/-0.082) for {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'n_estimators': 10}\n",
      "0.810 (+/-0.082) for {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'n_estimators': 50}\n",
      "0.796 (+/-0.035) for {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'n_estimators': 10}\n",
      "0.785 (+/-0.043) for {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'n_estimators': 50}\n",
      "0.808 (+/-0.083) for {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 10}\n",
      "0.815 (+/-0.073) for {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 50}\n",
      "0.787 (+/-0.036) for {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'n_estimators': 10}\n",
      "0.789 (+/-0.053) for {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'n_estimators': 50}\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.90      0.87       105\n",
      "          1       0.84      0.76      0.79        74\n",
      "\n",
      "avg / total       0.84      0.84      0.84       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 8\n",
    "random_search = RandomizedSearchCV(RandomForestClassifier(), param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X_train_sc, y_train)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "y_true, y_pred = y_test, random_search.predict(X_test_sc)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimators': 1, 'learning_rate': 10.0, 'score': 0.82691873463000221}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "highest = dict()\n",
    "a = []\n",
    "max_estimators = 50\n",
    "init = 1\n",
    "\n",
    "for i in range(1, max_estimators):\n",
    "    score = cross_val_score(GradientBoostingClassifier(n_estimators=i, learning_rate=10.0/float(i)), \n",
    "                        X_train_sc, y_train, cv=10, scoring='accuracy').mean()\n",
    "#     print('learning rate:', 10.0/float(i), 'estimators:', i, 'score:', score)\n",
    "    \n",
    "    if init == 1:\n",
    "        highest['score'] = score\n",
    "        highest['learning_rate'] = 10.0/float(i)\n",
    "        highest['estimators'] = i\n",
    "        init += 1\n",
    "    \n",
    "    if score > highest['score']:\n",
    "        highest['score'] = score\n",
    "        \n",
    "    a.append(score)\n",
    "highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.843 (+/-0.077) for {'C': 0.1}\n",
      "0.843 (+/-0.081) for {'C': 0.3}\n",
      "0.844 (+/-0.081) for {'C': 0.5}\n",
      "0.844 (+/-0.081) for {'C': 0.7}\n",
      "0.844 (+/-0.082) for {'C': 1}\n",
      "0.844 (+/-0.082) for {'C': 10}\n",
      "0.844 (+/-0.082) for {'C': 100}\n",
      "0.844 (+/-0.082) for {'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.82      0.83       105\n",
      "          1       0.75      0.78      0.77        74\n",
      "\n",
      "avg / total       0.81      0.80      0.80       179\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 0.1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.802 (+/-0.094) for {'C': 0.1}\n",
      "0.794 (+/-0.095) for {'C': 0.3}\n",
      "0.795 (+/-0.090) for {'C': 0.5}\n",
      "0.795 (+/-0.090) for {'C': 0.7}\n",
      "0.795 (+/-0.090) for {'C': 1}\n",
      "0.792 (+/-0.101) for {'C': 10}\n",
      "0.792 (+/-0.101) for {'C': 100}\n",
      "0.792 (+/-0.101) for {'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.84      0.84       105\n",
      "          1       0.77      0.77      0.77        74\n",
      "\n",
      "avg / total       0.81      0.81      0.81       179\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'C': [0.1, 0.3, 0.5, 0.7, 1, 10, 100, 1000]}]\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "scores = ['roc_auc', 'accuracy']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(LogisticRegression(random_state=1), tuned_parameters, cv=5,\n",
    "                       scoring=score)\n",
    "    clf.fit(X_train_sc, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test_sc)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived\n",
      "0          892         0\n",
      "1          893         1\n",
      "2          894         0\n",
      "3          895         0\n",
      "4          896         1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr = GradientBoostingClassifier(n_estimators=1, learning_rate=10)\n",
    "gr.fit(X_train_sc, y_train)\n",
    "\n",
    "predictions = gr.predict(test)\n",
    "\n",
    "\n",
    "output = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\n",
    "output.to_csv('titanic-predictions.csv', index = False)\n",
    "print(output.head())\n",
    "len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
